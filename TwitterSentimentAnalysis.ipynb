{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyAn_qNlomUg",
        "outputId": "d48d35a8-b273-4292-cb3e-bd78eefb26fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.2.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Installing collected packages: reportlab\n",
            "Successfully installed reportlab-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unZb66vfn99G",
        "outputId": "7d1f5070-a0a5-4362-e9fb-8397fd4d68a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-83e008b9cfe4>:84: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img = img.resize((max_width, h_size), PILImage.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Generated Successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, PageBreak\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from wordcloud import WordCloud\n",
        "from textblob import TextBlob\n",
        "import os\n",
        "\n",
        "def load_data(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    return df\n",
        "\n",
        "def generate_visualizations(df):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "\n",
        "    # Visualization 1: Distribution of Labels\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.countplot(x='label', data=df)\n",
        "    plt.title('Distribution of Tweets by Label')\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Count')\n",
        "    plt.savefig('distribution_of_tweets_by_label.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Visualization 2: Length of Tweets\n",
        "    df['tweet_length'] = df['tweet'].apply(len)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df['tweet_length'], bins=30, kde=True)\n",
        "    plt.title('Distribution of Tweet Length')\n",
        "    plt.xlabel('Tweet Length')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.savefig('tweet_length_distribution.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Visualization 3: Boxplot of Tweet Length by Label\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(x='label', y='tweet_length', data=df)\n",
        "    plt.title('Tweet Length by Label')\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Tweet Length')\n",
        "    plt.xticks([0, 1], ['Positive tweets', 'Negative tweets'])\n",
        "    plt.savefig('tweet_length_by_label.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Generate and save wordclouds for each sentiment\n",
        "    grouped_tweets = df.groupby('sentiment')['tweet'].apply(lambda tweets: ' '.join(tweets)).to_dict()\n",
        "    for sentiment, tweets in grouped_tweets.items():\n",
        "        wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(tweets)\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Word Cloud for {sentiment.capitalize()} Sentiment\")\n",
        "        plt.savefig(f'wordcloud_{sentiment}.png')\n",
        "        plt.close()\n",
        "\n",
        "def train_and_evaluate(df):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['label'], test_size=0.2, random_state=42)\n",
        "    pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    predictions = pipeline.predict(X_test)\n",
        "    report = classification_report(y_test, predictions, output_dict=True)\n",
        "    return report\n",
        "\n",
        "def save_report(report):\n",
        "    with open('classification_report.txt', 'w') as f:\n",
        "        f.write(str(report))\n",
        "\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "def resize_image(image_path, max_width=500, max_height=500):\n",
        "    with PILImage.open(image_path) as img:\n",
        "        w_percent = (max_width / float(img.size[0]))\n",
        "        h_size = int((float(img.size[1]) * float(w_percent)))\n",
        "        img = img.resize((max_width, h_size), PILImage.ANTIALIAS)\n",
        "\n",
        "        new_image_path = f\"resized_{image_path}\"\n",
        "        img.save(new_image_path)\n",
        "        return new_image_path\n",
        "\n",
        "def generate_pdf():\n",
        "    doc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = [Paragraph('Model Evaluation Report', styles['Title'])]\n",
        "\n",
        "    # Image files to include in the PDF\n",
        "    image_files = [\n",
        "        'distribution_of_tweets_by_label.png',\n",
        "        'tweet_length_distribution.png',\n",
        "        'tweet_length_by_label.png'\n",
        "    ]\n",
        "    sentiments = ['positive', 'negative', 'neutral']\n",
        "    image_files.extend([f'wordcloud_{sent}.png' for sent in sentiments])\n",
        "\n",
        "    # Add resized images and text reports to the PDF document\n",
        "    for image_path in image_files:\n",
        "        if os.path.exists(image_path):\n",
        "            resized_path = resize_image(image_path)\n",
        "            story.append(Image(resized_path))\n",
        "            story.append(PageBreak())\n",
        "\n",
        "    with open('classification_report.txt', 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    for line in lines:\n",
        "        story.append(Paragraph(line, styles['BodyText']))\n",
        "        story.append(Spacer(1, 12))\n",
        "\n",
        "    doc.build(story)\n",
        "    print(\"PDF Generated Successfully.\")\n",
        "\n",
        "def main():\n",
        "    df = load_data('train_tweets_data.csv')\n",
        "    df['sentiment'] = df['tweet'].apply(lambda x: 'positive' if TextBlob(x).sentiment.polarity > 0 else 'negative' if TextBlob(x).sentiment.polarity < 0 else 'neutral')\n",
        "    generate_visualizations(df)\n",
        "    report = train_and_evaluate(df)\n",
        "    save_report(report)\n",
        "    generate_pdf()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}